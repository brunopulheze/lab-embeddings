{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "This lab is designed to help you solidify your understanding of embeddings by applying them to tasks like semantic similarity, clustering, and building a semantic search system.\n",
    "\n",
    "### Tasks:\n",
    "- Task 1: Semantic Similarity Comparison\n",
    "- Task 2: Document Clustering\n",
    "- Task 3: Enhance the Semantic Search System\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Semantic Similarity Comparison\n",
    "### Objective:\n",
    "Compare semantic similarity between pairs of sentences using cosine similarity and embeddings.\n",
    "\n",
    "### Steps:\n",
    "1. Load a pre-trained Sentence Transformer model.\n",
    "2. Encode the sentence pairs.\n",
    "3. Compute cosine similarity for each pair.\n",
    "\n",
    "### Dataset:\n",
    "- \"A dog is playing in the park.\" vs. \"A dog is running in a field.\"\n",
    "- \"I love pizza.\" vs. \"I enjoy ice cream.\"\n",
    "- \"What is AI?\" vs. \"How does a computer learn?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between:\n",
      "  'A dog is playing in the park.'\n",
      "  'A dog is running in a field.'\n",
      "  = 0.5220\n",
      "\n",
      "Similarity between:\n",
      "  'I love pizza.'\n",
      "  'I enjoy ice cream.'\n",
      "  = 0.5281\n",
      "\n",
      "Similarity between:\n",
      "  'What is AI?'\n",
      "  'How does a computer learn?'\n",
      "  = 0.3194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "# Load pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Sentence pairs\n",
    "sentence_pairs = [\n",
    "    (\"A dog is playing in the park.\", \"A dog is running in a field.\"),\n",
    "    (\"I love pizza.\", \"I enjoy ice cream.\"),\n",
    "    (\"What is AI?\", \"How does a computer learn?\")\n",
    "]\n",
    "\n",
    "# Compute similarities\n",
    "for s1, s2 in sentence_pairs:\n",
    "    emb1 = model.encode([s1])\n",
    "    emb2 = model.encode([s2])\n",
    "    sim = cosine_similarity(emb1, emb2)[0][0]\n",
    "    print(f\"Similarity between:\\n  '{s1}'\\n  '{s2}'\\n  = {sim:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- Which sentence pairs are the most semantically similar? Why?\n",
    "- Can you think of cases where cosine similarity might fail to capture true semantic meaning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers to Task 1 Questions\n",
    "\n",
    "# 1. Which sentence pairs are the most semantically similar? Why?\n",
    "# The pair \"A dog is playing in the park.\" vs. \"A dog is running in a field.\" is the most semantically similar because both describe a dog engaging in a similar activity outdoors.\n",
    "\n",
    "# 2. Can you think of cases where cosine similarity might fail to capture true semantic meaning?\n",
    "# Cosine similarity may fail when sentences are paraphrased with very different vocabulary, or when context, sarcasm, or negation changes the meaning but embeddings remain close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Document Clustering\n",
    "### Objective:\n",
    "Cluster a set of text documents into similar groups based on their embeddings.\n",
    "\n",
    "### Steps:\n",
    "1. Encode the documents using Sentence Transformers.\n",
    "2. Use KMeans clustering to group the documents.\n",
    "3. Analyze the clusters for semantic meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Documents to cluster\n",
    "documents = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"How do I bake a chocolate cake?\",\n",
    "    \"What is the distance between Earth and Mars?\",\n",
    "    \"How do I change a flat tire on a car?\",\n",
    "    \"What is the best way to learn Python?\",\n",
    "    \"How do I fix a leaky faucet?\"\n",
    "]\n",
    "\n",
    "# Encode documents\n",
    "doc_embeddings = model.encode(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(doc_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 2: What is the capital of France?\n",
      "Cluster 0: How do I bake a chocolate cake?\n",
      "Cluster 0: What is the distance between Earth and Mars?\n",
      "Cluster 1: How do I change a flat tire on a car?\n",
      "Cluster 2: What is the best way to learn Python?\n",
      "Cluster 1: How do I fix a leaky faucet?\n"
     ]
    }
   ],
   "source": [
    "# Print cluster assignments\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"Cluster {clusters[i]}: {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- How many clusters make the most sense? Why?\n",
    "- Examine the documents in each cluster. Are they semantically meaningful? Can you assign a semantic \"theme\" to each cluster?\n",
    "- Try this exercise with a larger dataset of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "# 1. How many clusters make the most sense? Why?\n",
    "# Three clusters make sense here because the documents naturally group into three themes: factual questions, technical/how-to questions, and learning/education topics.\n",
    "\n",
    "# 2. Examine the documents in each cluster. Are they semantically meaningful? Can you assign a semantic \"theme\" to each cluster?\n",
    "# Yes, the clusters are meaningful. For example:\n",
    "# - Cluster 0: factual/science questions\n",
    "# - Cluster 1: car/home repair how-to\n",
    "# - Cluster 2: travel/learning/technology\n",
    "\n",
    "# 3. Try this exercise with a larger dataset of your choice.\n",
    "# With a larger dataset, clusters may become more refined and reveal additional themes. Try using a dataset like Stack Overflow questions or Wikipedia articles for richer clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Semantic Search System\n",
    "### Objective:\n",
    "Create a semantic search engine:\n",
    "A user provides a query and you search the dataset for semantically relevant documents to return. Return the top 5 results.\n",
    "\n",
    "### Dataset:\n",
    "- Use the following set of documents:\n",
    "    - \"What is the capital of France?\"\n",
    "    - \"How do I bake a chocolate cake?\"\n",
    "    - \"What is the distance between Earth and Mars?\"\n",
    "    - \"How do I change a flat tire on a car?\"\n",
    "    - \"What is the best way to learn Python?\"\n",
    "    - \"How do I fix a leaky faucet?\"\n",
    "    - \"What are the best travel destinations in Europe?\"\n",
    "    - \"How do I set up a local server?\"\n",
    "    - \"What is quantum computing?\"\n",
    "    - \"How do I build a mobile app?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Documents dataset\n",
    "documents = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"How do I bake a chocolate cake?\",\n",
    "    \"What is the distance between Earth and Mars?\",\n",
    "    \"How do I change a flat tire on a car?\",\n",
    "    \"What is the best way to learn Python?\",\n",
    "    \"How do I fix a leaky faucet?\",\n",
    "    \"What are the best travel destinations in Europe?\",\n",
    "    \"How do I set up a local server?\",\n",
    "    \"What is quantum computing?\",\n",
    "    \"How do I build a mobile app?\"\n",
    "]\n",
    "\n",
    "# Compute document embeddings\n",
    "doc_embeddings = model.encode(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the search function\n",
    "#This function should encode the user query and return the top N documents that most resemble it\n",
    "def semantic_search(query, documents, doc_embeddings, top_n=5):\n",
    "    query_emb = model.encode([query])\n",
    "    sims = cosine_similarity(query_emb, doc_embeddings)[0]\n",
    "    top_idx = np.argsort(sims)[::-1][:top_n]\n",
    "    print(f\"Query: {query}\\nTop {top_n} results:\")\n",
    "    for idx in top_idx:\n",
    "        print(f\"  ({sims[idx]:.4f}) {documents[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Explain programming languages.\n",
      "Top 5 results:\n",
      "  (0.4352) What is quantum computing?\n",
      "  (0.3188) What is the best way to learn Python?\n",
      "  (0.1104) How do I build a mobile app?\n",
      "  (0.0911) How do I set up a local server?\n",
      "  (0.0906) What are the best travel destinations in Europe?\n"
     ]
    }
   ],
   "source": [
    "# Test the search function\n",
    "query = \"Explain programming languages.\"\n",
    "semantic_search(query, documents, doc_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- What are the top-ranked results for the given queries?\n",
    "- How can you improve the ranking explanation for users?\n",
    "- Try this approach with a larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. What are the top-ranked results for the given queries?\n",
    "# The top-ranked results are those documents with the highest cosine similarity to the query embedding. For \"Explain programming languages.\", results related to learning Python or building a mobile app are likely to be top-ranked.\n",
    "\n",
    "# 2. How can you improve the ranking explanation for users?\n",
    "# You can display similarity scores, highlight matching keywords, or provide a short summary explaining why each result is relevant to the query.\n",
    "\n",
    "# 3. Try this approach with a larger dataset\n",
    "# Using a larger dataset will improve the diversity and relevance of search results, making the semantic search more useful and robust."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
